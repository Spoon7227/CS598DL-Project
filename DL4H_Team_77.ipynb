{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01aH0PR4Sg-"
      },
      "source": [
        "# Before you use this template\n",
        "\n",
        "This template is just a recommended template for project Report. It only considers the general type of research in our paper pool. Feel free to edit it to better fit your project. You will iteratively update the same notebook submission for your draft and the final submission. Please check the project rubriks to get a sense of what is expected in the template.\n",
        "\n",
        "---\n",
        "\n",
        "# FAQ and Attentions\n",
        "* Copy and move this template to your Google Drive. Name your notebook by your team ID (upper-left corner). Don't eidt this original file.\n",
        "* This template covers most questions we want to ask about your reproduction experiment. You don't need to exactly follow the template, however, you should address the questions. Please feel free to customize your report accordingly.\n",
        "* any report must have run-able codes and necessary annotations (in text and code comments).\n",
        "* The notebook is like a demo and only uses small-size data (a subset of original data or processed data), the entire runtime of the notebook including data reading, data process, model training, printing, figure plotting, etc,\n",
        "must be within 8 min, otherwise, you may get penalty on the grade.\n",
        "  * If the raw dataset is too large to be loaded  you can select a subset of data and pre-process the data, then, upload the subset or processed data to Google Drive and load them in this notebook.\n",
        "  * If the whole training is too long to run, you can only set the number of training epoch to a small number, e.g., 3, just show that the training is runable.\n",
        "  * For results model validation, you can train the model outside this notebook in advance, then, load pretrained model and use it for validation (display the figures, print the metrics).\n",
        "* The post-process is important! For post-process of the results,please use plots/figures. The code to summarize results and plot figures may be tedious, however, it won't be waste of time since these figures can be used for presentation. While plotting in code, the figures should have titles or captions if necessary (e.g., title your figure with \"Figure 1. xxxx\")\n",
        "* There is not page limit to your notebook report, you can also use separate notebooks for the report, just make sure your grader can access and run/test them.\n",
        "* If you use outside resources, please refer them (in any formats). Include the links to the resources if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "# Introduction\n",
        "This is an introduction to your report, you should edit this text/mardown section to compose. In this text/markdown, you should introduce:\n",
        "\n",
        "*   Background of the problem\n",
        "  * what type of problem: disease/readmission/mortality prediction,  feature engineeing, data processing, etc\n",
        "  * what is the importance/meaning of solving the problem\n",
        "  * what is the difficulty of the problem\n",
        "  * the state of the art methods and effectiveness.\n",
        "*   Paper explanation\n",
        "  * what did the paper propose\n",
        "  * what is the innovations of the method\n",
        "  * how well the proposed method work (in its own metrics)\n",
        "  * what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABD4VhFZbehA"
      },
      "outputs": [],
      "source": [
        "# code comment is used as inline annotations for your coding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
        "\n",
        "1.   Hypothesis: The DuETT's attention to both time and event types will yield more comprehensive EHR data representations and result in improved performance over other methods (XGBoost, LSTM, mTAND, Raindrop, STraTs) on the PhysioNet-2012 mortality task.\n",
        "\n",
        "Experiments:\n",
        "\n",
        "1. We will run the DuETT model on the PhysioNet-2012 mortality task using the same training parameter inorder to validate and replicate the original paper result.\n",
        "\n",
        "Ablations planned:\n",
        "\n",
        "1.   Input representation ablations: \n",
        "      - Investigate the use of the last occurring value in the bin as the aggregation functions of bins by comparing the performance with other methods (mean, max). \n",
        "      - Investigate the choice of injecting event & time embedding at each layer which should by only injecting at the first layer.\n",
        "2.   Self-Supervised Learning Ablation: \n",
        "      - Investigate the impact of pre-training by skipping it entirely.\n",
        "3.   Dual event & time transformer Ablation: \n",
        "      - Investigate the impact of having both event and time transformers by only having either event or time transformers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchmetrics\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import x_transformers\n",
        "\n",
        "# Code based on Authors' Public Repository\n",
        "import duett\n",
        "import physionet\n",
        "import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 2020\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2020"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use same seed as paper\n",
        "\n",
        "seed = 2020\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "##  Data\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset\n",
        "\n",
        "The PhysioNet/Computing in Cardiology Challenge 2012: Predicting Mortality of ICU Patients\n",
        "\n",
        "### Source of Data\n",
        "\n",
        "This data consists of records from 12000 ICU stays and is accessed for this project through torchtime.data as well as from the official physionet website: https://physionet.org/content/challenge-2012/1.0.0/\n",
        "\n",
        "### Data Descriptors\n",
        "\n",
        "1. 37 Time Series Variales:\n",
        "\n",
        "    0. Mins: Minutes since ICU admission. Derived from the PhysioNet time stamp.\n",
        "    1. Albumin: Albumin (g/dL)\n",
        "    2. ALP: Alkaline phosphatase (IU/L)\n",
        "    3. ALT: Alanine transaminase (IU/L)\n",
        "    4. AST: Aspartate transaminase (IU/L)\n",
        "    5. Bilirubin: Bilirubin (mg/dL)\n",
        "    6. BUN: Blood urea nitrogen (mg/dL)\n",
        "    7. Cholesterol: Cholesterol (mg/dL)\n",
        "    8. Creatinine: Serum creatinine (mg/dL)\n",
        "    9. DiasABP: Invasive diastolic arterial blood pressure (mmHg)\n",
        "    10. FiO2: Fractional inspired O\\ :sub:`2` (0-1)\n",
        "    11. GCS: Glasgow Coma Score (3-15)\n",
        "    12. Glucose: Serum glucose (mg/dL)\n",
        "    13. HCO3: Serum bicarbonate (mmol/L)\n",
        "    14. HCT: Hematocrit (%)\n",
        "    15. HR: Heart rate (bpm)\n",
        "    16. K: Serum potassium (mEq/L)\n",
        "    17. Lactate: Lactate (mmol/L)\n",
        "    18. Mg: Serum magnesium (mmol/L)\n",
        "    19. MAP: Invasive mean arterial blood pressure (mmHg)\n",
        "    20. MechVent: Mechanical ventilation respiration (0:false, or 1:true)\n",
        "    21. Na: Serum sodium (mEq/L)\n",
        "    22. NIDiasABP: Non-invasive diastolic arterial blood pressure (mmHg)\n",
        "    23. NIMAP: Non-invasive mean arterial blood pressure (mmHg)\n",
        "    24. NISysABP: Non-invasive systolic arterial blood pressure (mmHg)\n",
        "    25. PaCO2: Partial pressure of arterial CO\\ :sub:`2` (mmHg)]\n",
        "    26. PaO2: Partial pressure of arterial O\\ :sub:`2` (mmHg)\n",
        "    27. pH: Arterial pH (0-14)\n",
        "    28. Platelets: Platelets (cells/nL)\n",
        "    29. RespRate: Respiration rate (bpm)\n",
        "    30. SaO2: O\\ :sub:`2` saturation in hemoglobin (%)\n",
        "    31. SysABP: Invasive systolic arterial blood pressure (mmHg)\n",
        "    32. Temp: Temperature (°C)\n",
        "    33. TroponinI: Troponin-I (μg/L). Note this is labelled *TropI* in the PhysioNet\n",
        "        data dictionary.\n",
        "    34. TroponinT: Troponin-T (μg/L). Note this is labelled *TropT* in the PhysioNet\n",
        "        data dictionary.\n",
        "    35. Urine: Urine output (mL)\n",
        "    36. WBC: White blood cell count (cells/nL)\n",
        "\n",
        "2. General Descriptors:\n",
        "\n",
        "    37. Weight: Weight (kg)\n",
        "    38. Age: Age (years) at ICU admission\n",
        "    39. Gender: Gender (0: female, or 1: male)\n",
        "    40. Height: Height (cm) at ICU admission\n",
        "    41. ICUType1: Type of ICU unit (1: Coronary Care Unit)\n",
        "    42. ICUType2: Type of ICU unit (2: Cardiac Surgery Recovery Unit)\n",
        "    43. ICUType3: Type of ICU unit (3: Medical ICU)\n",
        "    44. ICUType4: Type of ICU unit (4: Surgical ICU)\n",
        "\n",
        "3. Outcome-related Descriptors\n",
        "\n",
        "    1. RecordID \n",
        "    2. SAPS-I score (Le Gall et al., 1984)\n",
        "    3. SOFA score (Ferreira et al., 2001)\n",
        "    4. Length of stay (days)\n",
        "    5. Survival (days)\n",
        "    6. In-hospital death (0: survivor, or 1: died in-hospital)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://physionet.org/files/challenge-2012/1.0.0/set-a.zip?download...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7.57M/7.57M [00:11<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://physionet.org/files/challenge-2012/1.0.0/set-b.zip?download...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7.59M/7.59M [00:11<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://physionet.org/files/challenge-2012/1.0.0/set-c.tar.gz?download...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.29M/6.29M [00:09<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://physionet.org/files/challenge-2012/1.0.0/Outcomes-a.txt?download...\n",
            "Downloading https://physionet.org/files/challenge-2012/1.0.0/Outcomes-b.txt?download...\n",
            "Downloading https://physionet.org/files/challenge-2012/1.0.0/Outcomes-c.txt?download...\n",
            "Processing data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:02<00:00]\n",
            "100%|██████████| 4000/4000 [00:02<00:00]\n",
            "100%|██████████| 4000/4000 [00:02<00:00]\n",
            "100%|██████████| 4000/4000 [01:30<00:00]\n",
            "100%|██████████| 4000/4000 [01:31<00:00]\n",
            "100%|██████████| 4000/4000 [01:28<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating cache...\n",
            "Validating cache...\n"
          ]
        }
      ],
      "source": [
        "dm = physionet.PhysioNetDataModule(batch_size=512, num_workers=16, use_temp_cache=True)\n",
        "dm.setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sample Size:  12000\n",
            "Train Split:  8400  Val Split:  1800  Test Split:  1800\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_set = dm.ds_train\n",
        "val_set = dm.ds_val\n",
        "test_set = dm.ds_test\n",
        "\n",
        "total_size = len(train_set) + len(val_set) + len(test_set)\n",
        "\n",
        "print(\"Total Sample Size: \", total_size)\n",
        "print(\"Train Split: \", len(train_set), \" Val Split: \",  len(val_set), \" Test Split: \", len(test_set))\n",
        "\n",
        "# Label distribution\n",
        "count_0 = (train_set.y == 0).sum() + (val_set.y == 0).sum() + (test_set.y == 0).sum()\n",
        "percentage = (count_0 / total_size)\n",
        "\n",
        "plt.bar(['0', '1'], [percentage, 1 - percentage], color=['blue', 'orange'])\n",
        "plt.title('Label (0, 1) Distribution')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Process\n",
        "\n",
        "### Splitting Data\n",
        "\n",
        "This Physio2012 has predefined train/val/test splits given when loading data \n",
        "\n",
        "\n",
        "### Input Representation Processing\n",
        "\n",
        "Input data X includes 37 Time Series data and 6 General Descriptors. \n",
        "\n",
        "We process the 37 Time Series data by splitting the full sequence of each of the patient's time series event into equal lengthed bins. This results in a 2d binned input matrix of shape (37 event type, # bins) where each bin contains a value that is the aggregation of values that occured within that bin's time frame. This aggregation can be the mean, max, min or last value observed for that bin.\n",
        "\n",
        "This transforms the irregular input data into regularly sampled data with bin number acting as a control over the trade-off between information granularity and computational complexity.\n",
        "\n",
        "We seperatly collect the General Descriptors as static input\n",
        "\n",
        "Final x representation:\n",
        "  -  x = (Binned event values, General Descriptors, Bin Boundaries)\n",
        "\n",
        "Final y representation:\n",
        "  -  y = In-hospital death (0: survivor, or 1: died in-hospital)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: (Binned event values, General Descriptors, Bin Boundaries)\n",
            "x Shape:  (torch.Size([32, 72]), torch.Size([8]), torch.Size([32]))\n"
          ]
        }
      ],
      "source": [
        "# Code snippet for processing each data point (x, y) based on public repo\n",
        "\n",
        "def __getitem__(self, i):\n",
        "    ins = self.X[i, ~torch.isnan(self.X[i,:,0]), :]\n",
        "    time = ins[:,0] / 60 / 24\n",
        "    x_static = torch.zeros(self.d_static_num())\n",
        "\n",
        "\t# Split patient events into bins of equal length, and use last ocurring value in each bin as representative value\n",
        "    x_ts = torch.zeros((self.n_timesteps, self.d_time_series_num()*2))\n",
        "    for i_t, t in enumerate(time):\n",
        "        bin = self.n_timesteps - 1 if t == time[-1] else int(t / time[-1] * self.n_timesteps)\n",
        "        for i_ts in range(1,37):\n",
        "            x_i = ins[i_t,i_ts]\n",
        "            if not torch.isnan(x_i).item():\n",
        "                x_ts[bin, i_ts-1] = (x_i - self.means[i_ts])/(self.stds[i_ts] + 1e-7)\n",
        "                x_ts[bin, i_ts-1+self.d_time_series_num()] += 1\n",
        "    bin_ends = torch.arange(1, self.n_timesteps+1) / self.n_timesteps * time[-1]\n",
        "\n",
        "\t# Collect General Descriptors as static input variables\n",
        "    for i_tab in range(37,45):\n",
        "        x_i = ins[0, i_tab]\n",
        "        x_i = (x_i - self.means[i_tab])/(self.stds[i_tab] + 1e-7)\n",
        "        x_static[i_tab-37] = x_i.nan_to_num(0.)\n",
        "\n",
        "\t# Final x representation, (Binned event values, General Descriptors, Bin Boundaries)\n",
        "    x = (x_ts, x_static, bin_ends)\n",
        "    \n",
        "\t# Final y representation, (0: survivor, or 1: died in-hospital)\n",
        "    y = self.y[i,0]\n",
        "    if self.temp_cache is not None:\n",
        "        self.temp_cache[i] = (x, y)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "x, y  = dm.ds_train.__getitem__(0)\n",
        "\n",
        "print(\"x: (Binned event values, General Descriptors, Bin Boundaries)\")\n",
        "print(\"x Shape: \", (x[0].shape, x[1].shape, x[2].shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3muyDPFPbozY"
      },
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture:\n",
        "\n",
        "Model Architecture is implemented and imported from duett.py (Based on Public Paper Repo)\n",
        "\n",
        "The model consists of a series of DuETT layers followed by classification or self-supervised learning heads.  Each DuETT layer has 2 transformer sublayers that attend to the event and time dimension of the embedding respectively.\n",
        "\n",
        "The first sublayer (Event transformer) has a multi-head attention over events followed by a feed-forward network in the event dimension.\n",
        "\n",
        "The second sublayer (Time transformer) has a multi-head attention over time bins followed by a feed-forward network operating along the time dimension\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretraining\n",
        "\n",
        "Uses masked event modeling to train the model to capture important priors. This masking scheme is done along both time and event dimensions and predicts both the presence and absence of an event. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "warmup_steps 2000, base_lr None, invsqrt True, decay None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/josephjang/opt/anaconda3/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/Users/josephjang/opt/anaconda3/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "ename": "MisconfigurationException",
          "evalue": "GPUAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu'].",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-0f0823fbf08d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_top_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwarmup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWarmUpCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m trainer = pl.Trainer(gpus=1, logger=False, num_sanity_val_steps=2, max_epochs=300,\n\u001b[0m\u001b[1;32m      9\u001b[0m         gradient_clip_val=1.0, callbacks=[warmup, checkpoint])\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_connector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple_trainloader_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         self._accelerator_connector = AcceleratorConnector(\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_parallel_devices_and_init_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# 3. Instantiate ClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m_set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0macc_str\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0macc_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_types\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mAcceleratorRegistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             ]\n\u001b[0;32m--> 514\u001b[0;31m             raise MisconfigurationException(\n\u001b[0m\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"{self.accelerator.__class__.__qualname__} can not run on your system\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;34m\" since the accelerator is not available. The following accelerator(s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMisconfigurationException\u001b[0m: GPUAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
          ]
        }
      ],
      "source": [
        "# Pre-training Code\n",
        "\n",
        "pretrain_model = duett.pretrain_model(d_static_num=dm.d_static_num(),\n",
        "        d_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(),\n",
        "        seed=seed)\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(save_last=True, monitor='val_loss', mode='min', save_top_k=1, dirpath='checkpoints')\n",
        "warmup = train.WarmUpCallback(steps=2000)\n",
        "trainer = pl.Trainer(gpus=1, logger=False, num_sanity_val_steps=2, max_epochs=300,\n",
        "        gradient_clip_val=1.0, callbacks=[warmup, checkpoint])\n",
        "trainer.fit(pretrain_model, dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBdVZoTvsSFV"
      },
      "outputs": [],
      "source": [
        "\n",
        "class my_model():\n",
        "  # use this class to define your model\n",
        "  pass\n",
        "\n",
        "model = my_model()\n",
        "loss_func = None\n",
        "optimizer = None\n",
        "\n",
        "def train_model_one_iter(model, loss_func, optimizer):\n",
        "  pass\n",
        "\n",
        "num_epoch = 10\n",
        "# model training loop: it is better to print the training/validation losses during the training\n",
        "for i in range(num_epoch):\n",
        "  train_model_one_iter(model, loss_func, optimizer)\n",
        "  train_loss, valid_loss = None, None\n",
        "  print(\"Train Loss: %.2f, Validation Loss: %.2f\" % (train_loss, valid_loss))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Results\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "outputs": [],
      "source": [
        "# metrics to evaluate my model\n",
        "\n",
        "# plot figures to better show the results\n",
        "\n",
        "# it is better to save the numbers and figures for your presentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAWAy_LwHlV"
      },
      "source": [
        "## Model comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "outputs": [],
      "source": [
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2VDXo5F4Frm"
      },
      "outputs": [],
      "source": [
        "# no code is required for this section\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can read and plot it here like the Scope of Reproducibility\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1.   Sun, J, [paper title], [journal title], [year], [volume]:[issue], doi: [doi link to paper]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVuzQ724HbO"
      },
      "source": [
        "# Feel free to add new sections"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
