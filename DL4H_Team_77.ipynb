{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "## CS598DL4 Final Project Team 77\n",
        "\n",
        "# DuETT: Dual Event Time Transformer for Electronic Health Records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Project Github Link: https://github.com/Spoon7227/CS598DL-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "Electronic health records contain a wide range of time series data that is sparse and irregular which makes it hard to effectively model especially when considering the semantic relationship between different types of observations. Self-supervised transformers perform well with data with structured relationships, but straightforward applications struggle with EHRs due to it’s a structured relationship over 2 dimensions of time and recorded events. Self-attention layer’s quadratic scaling also limits the input data length. This paper aims to solve this problem by showcases the novel dual event time transformer (DueTT) approach for the task of mortality prediction.\n",
        "\n",
        "This paper proposes 3 main novel methods.\n",
        "\n",
        "Input representation: Input representation that incorporates event information (ex: frequency, missingness, …), uses early fusion of static variables of the patient (age, sex, ...), and aggregates observations. To be more specific, each event type is binned into time bins of equal duration to tackle the irregular and sparse nature of EHR time series data, this is then mapped to an embedding. Lastly, static variables are concatenated to the embeddings so each bin has access to that information. \n",
        "\n",
        "DuETT Architecture: Each DuETT layer has 2 transformer sublayers that attend to the event and time dimension of the embedding respectively. The overall model has multiple DuETT sublayers that is followed by self-supervised learning heads. This allows for the model to capture both the types of events and the time in which they are observed.\n",
        "\n",
        "Self-supervised training: Perform pre-training that uses masked event modeling to train the model to capture important priors. This masking scheme is done along both time and event dimensions and predicts both the presence and absence of an event. Then, fine-tuning is done in a supervised manner. \n",
        "\n",
        "It is showcased that the DuETT's attention to both time and event types will yield more comprehensive EHR data representations and result in improved performance over other methods (XGBoost, LSTM, mTAND, Raindrop, STraTs) on the PhysioNet-2012 mortality task, achieving a AUROC of 0.872 ± 0.001 and Avg Precision of  0.564 ± 0.003.\n",
        "\n",
        "This paper contributes to the research regime by proposing a transformer architecture and input transformation method that addresses both the hard to model nature of time-series data of EHR, and the limit of input data length on self-attention model complexity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "Hypothesis: The DuETT's attention to both time and event types will yield more comprehensive EHR data representations and result in improved performance over other methods (XGBoost, LSTM, mTAND, Raindrop, STraTs) on the PhysioNet-2012 mortality task.\n",
        "\n",
        "Experiments:\n",
        "\n",
        "1. We will run the DuETT model on the PhysioNet-2012 mortality task using the same training parameter inorder to validate and replicate the original paper result.\n",
        "\n",
        "Ablations planned:\n",
        "\n",
        "1.   Input representation ablations: \n",
        "      - Investigate the use of the last occurring value in the bin as the aggregation functions of bins by comparing the performance with other methods (mean, max). \n",
        "      - Investigate the choice of injecting event & time embedding at each layer which should by only injecting at the first layer.\n",
        "2.   Self-Supervised Learning Ablation: \n",
        "      - Investigate the impact of pre-training by skipping it entirely.\n",
        "3.   Dual event & time transformer Ablation: \n",
        "      - Investigate the impact of having both event and time transformers by only having either event or time transformers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "outputs": [],
      "source": [
        "# Used python version 3.9.18\n",
        "\n",
        "# Install necessary packages\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "# Torch with Cuda for GPU training\n",
        "# %pip install torch==1.13.1+cu117 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchmetrics\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import x_transformers\n",
        "import matplotlib.image as mpimg\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "import os\n",
        "\n",
        "# Code based on Authors' Public Repository\n",
        "import duett\n",
        "import physionet\n",
        "import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use same seed as paper\n",
        "seed = 2020\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flag to enable / Disable Training \n",
        "training = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "##  Data\n",
        "Data includes raw data, descriptive statistics, and data processing.\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset\n",
        "\n",
        "The PhysioNet/Computing in Cardiology Challenge 2012: Predicting Mortality of ICU Patients\n",
        "\n",
        "### Source of Data\n",
        "\n",
        "This data consists of records from 12000 ICU stays and is accessed for this project through torchtime.data as well as from the official physionet website: https://physionet.org/content/challenge-2012/1.0.0/\n",
        "\n",
        "### Data Descriptors\n",
        "\n",
        "1. 37 Time Series Variales:\n",
        "\n",
        "    0. Mins: Minutes since ICU admission. Derived from the PhysioNet time stamp.\n",
        "    1. Albumin: Albumin (g/dL)\n",
        "    2. ALP: Alkaline phosphatase (IU/L)\n",
        "    3. ALT: Alanine transaminase (IU/L)\n",
        "    4. AST: Aspartate transaminase (IU/L)\n",
        "    5. Bilirubin: Bilirubin (mg/dL)\n",
        "    6. BUN: Blood urea nitrogen (mg/dL)\n",
        "    7. Cholesterol: Cholesterol (mg/dL)\n",
        "    8. Creatinine: Serum creatinine (mg/dL)\n",
        "    9. DiasABP: Invasive diastolic arterial blood pressure (mmHg)\n",
        "    10. FiO2: Fractional inspired O\\ :sub:`2` (0-1)\n",
        "    11. GCS: Glasgow Coma Score (3-15)\n",
        "    12. Glucose: Serum glucose (mg/dL)\n",
        "    13. HCO3: Serum bicarbonate (mmol/L)\n",
        "    14. HCT: Hematocrit (%)\n",
        "    15. HR: Heart rate (bpm)\n",
        "    16. K: Serum potassium (mEq/L)\n",
        "    17. Lactate: Lactate (mmol/L)\n",
        "    18. Mg: Serum magnesium (mmol/L)\n",
        "    19. MAP: Invasive mean arterial blood pressure (mmHg)\n",
        "    20. MechVent: Mechanical ventilation respiration (0:false, or 1:true)\n",
        "    21. Na: Serum sodium (mEq/L)\n",
        "    22. NIDiasABP: Non-invasive diastolic arterial blood pressure (mmHg)\n",
        "    23. NIMAP: Non-invasive mean arterial blood pressure (mmHg)\n",
        "    24. NISysABP: Non-invasive systolic arterial blood pressure (mmHg)\n",
        "    25. PaCO2: Partial pressure of arterial CO\\ :sub:`2` (mmHg)]\n",
        "    26. PaO2: Partial pressure of arterial O\\ :sub:`2` (mmHg)\n",
        "    27. pH: Arterial pH (0-14)\n",
        "    28. Platelets: Platelets (cells/nL)\n",
        "    29. RespRate: Respiration rate (bpm)\n",
        "    30. SaO2: O\\ :sub:`2` saturation in hemoglobin (%)\n",
        "    31. SysABP: Invasive systolic arterial blood pressure (mmHg)\n",
        "    32. Temp: Temperature (°C)\n",
        "    33. TroponinI: Troponin-I (μg/L). Note this is labelled *TropI* in the PhysioNet\n",
        "        data dictionary.\n",
        "    34. TroponinT: Troponin-T (μg/L). Note this is labelled *TropT* in the PhysioNet\n",
        "        data dictionary.\n",
        "    35. Urine: Urine output (mL)\n",
        "    36. WBC: White blood cell count (cells/nL)\n",
        "\n",
        "2. General Descriptors:\n",
        "\n",
        "    37. Weight: Weight (kg)\n",
        "    38. Age: Age (years) at ICU admission\n",
        "    39. Gender: Gender (0: female, or 1: male)\n",
        "    40. Height: Height (cm) at ICU admission\n",
        "    41. ICUType1: Type of ICU unit (1: Coronary Care Unit)\n",
        "    42. ICUType2: Type of ICU unit (2: Cardiac Surgery Recovery Unit)\n",
        "    43. ICUType3: Type of ICU unit (3: Medical ICU)\n",
        "    44. ICUType4: Type of ICU unit (4: Surgical ICU)\n",
        "\n",
        "3. Outcome-related Descriptors\n",
        "\n",
        "    1. RecordID \n",
        "    2. SAPS-I score (Le Gall et al., 1984)\n",
        "    3. SOFA score (Ferreira et al., 2001)\n",
        "    4. Length of stay (days)\n",
        "    5. Survival (days)\n",
        "    6. In-hospital death (0: survivor, or 1: died in-hospital)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dm = physionet.PhysioNetDataModule(batch_size=512, num_workers=16, use_temp_cache=True)\n",
        "dm.setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = dm.ds_train\n",
        "val_set = dm.ds_val\n",
        "test_set = dm.ds_test\n",
        "\n",
        "total_size = len(train_set) + len(val_set) + len(test_set)\n",
        "\n",
        "print(\"Total Sample Size: \", total_size)\n",
        "print(\"Train Split: \", len(train_set), \" Val Split: \",  len(val_set), \" Test Split: \", len(test_set))\n",
        "\n",
        "# Label distribution\n",
        "count_0 = (train_set.y == 0).sum() + (val_set.y == 0).sum() + (test_set.y == 0).sum()\n",
        "percentage = (count_0 / total_size)\n",
        "\n",
        "plt.bar(['0', '1'], [percentage, 1 - percentage], color=['blue', 'orange'])\n",
        "plt.title('Label (0: survivor, or 1: died in-hospital) Distribution')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Process\n",
        "\n",
        "### Splitting Data\n",
        "\n",
        "We use torchtime to load Physio2012 data with predefined train/val/test splits (70%, 15%, 15%)\n",
        "\n",
        "\n",
        "### Input Representation Processing\n",
        "\n",
        "Input data X includes 37 Time Series data and 6 General Descriptors. \n",
        "\n",
        "We process the 37 Time Series data by splitting the full sequence of each of the patient's time series event into equal lengthed bins. This results in a 2d binned input matrix of shape (37 event type, # bins) where each bin contains a value that is the aggregation of values that occured within that bin's time frame. This aggregation can be the mean, max, min or last value observed for that bin.\n",
        "\n",
        "This transforms the irregular input data into regularly sampled data with bin number acting as a control over the trade-off between information granularity and computational complexity.\n",
        "\n",
        "We seperatly collect the General Descriptors as static input\n",
        "\n",
        "Final x representation:\n",
        "  -  x = (Binned event values, General Descriptors, Bin Boundaries)\n",
        "\n",
        "Final y representation:\n",
        "  -  y = In-hospital death (0: survivor, or 1: died in-hospital)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code snippet for processing each data point (x, y) based on public repo\n",
        "\n",
        "def __getitem__(self, i):\n",
        "    ins = self.X[i, ~torch.isnan(self.X[i,:,0]), :]\n",
        "    time = ins[:,0] / 60 / 24\n",
        "    x_static = torch.zeros(self.d_static_num())\n",
        "\n",
        "\t# Split patient events into bins of equal length, and use last ocurring value in each bin as representative value\n",
        "    x_ts = torch.zeros((self.n_timesteps, self.d_time_series_num()*2))\n",
        "    for i_t, t in enumerate(time):\n",
        "        bin = self.n_timesteps - 1 if t == time[-1] else int(t / time[-1] * self.n_timesteps)\n",
        "        for i_ts in range(1,37):\n",
        "            x_i = ins[i_t,i_ts]\n",
        "            if not torch.isnan(x_i).item():\n",
        "                x_ts[bin, i_ts-1] = (x_i - self.means[i_ts])/(self.stds[i_ts] + 1e-7)\n",
        "                x_ts[bin, i_ts-1+self.d_time_series_num()] += 1\n",
        "    bin_ends = torch.arange(1, self.n_timesteps+1) / self.n_timesteps * time[-1]\n",
        "\n",
        "\t# Collect General Descriptors as static input variables\n",
        "    for i_tab in range(37,45):\n",
        "        x_i = ins[0, i_tab]\n",
        "        x_i = (x_i - self.means[i_tab])/(self.stds[i_tab] + 1e-7)\n",
        "        x_static[i_tab-37] = x_i.nan_to_num(0.)\n",
        "\n",
        "\t# Final x representation, (Binned event values, General Descriptors, Bin Boundaries)\n",
        "    x = (x_ts, x_static, bin_ends)\n",
        "    \n",
        "\t# Final y representation, (0: survivor, or 1: died in-hospital)\n",
        "    y = self.y[i,0]\n",
        "    if self.temp_cache is not None:\n",
        "        self.temp_cache[i] = (x, y)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "print(\"Raw Input Example: \")\n",
        "raw_x = dm.ds_train.X[0]\n",
        "print(\"x: (time series dimension, 37+8 Event/Descriptor)\")\n",
        "print(\"x Shape: \", raw_x.shape)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Post-Processed Input Example: \")\n",
        "x, y  = dm.ds_train.__getitem__(0)\n",
        "\n",
        "print(\"x: (Binned event values, General Descriptors, Bin Boundaries)\")\n",
        "print(\"x Shape: \", (x[0].shape, x[1].shape, x[2].shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3muyDPFPbozY"
      },
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture:\n",
        "\n",
        "Model Architecture is implemented and imported from duett.py (Based on Public Paper Repo)\n",
        "\n",
        "The model consists of a series of DuETT layers followed by classification or self-supervised learning heads.  Each DuETT layer has 2 transformer sublayers that attend to the event and time dimension of the embedding respectively.\n",
        "\n",
        "The first sublayer (Event transformer) has a multi-head attention over events followed by a feed-forward network in the event dimension.\n",
        "\n",
        "The second sublayer (Time transformer) has a multi-head attention over time bins followed by a feed-forward network operating along the time dimension\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Code Snippet:\n",
        "\n",
        "```\n",
        "\t# For any special timesteps, e.g., masked, static, [CLS], etc.\n",
        "\n",
        "\tself.special_embeddings = nn.Embedding(8, d_embedding)\n",
        "\n",
        "\t# Create list of MLP for embedding each event time series\n",
        "\n",
        "\tself.embedding_layers = nn.ModuleList([\n",
        "\t\tsimple_mlp(2, d_embedding, n_hidden_mlp_embedding, d_hidden_mlp_embedding, hidden_batch_norm=True)\n",
        "\t\tfor _ in range(d_time_series_num)])\n",
        "\n",
        "\t# Embedding for number of observations\n",
        "\n",
        "\tself.n_obs_embedding = nn.Embedding(16, 1)\n",
        "\n",
        "\tif d_feedforward is None:\n",
        "\t\td_feedforward = d_embedding * 4\n",
        "\n",
        "\t# Calculate dimensions for event and time transformer inputs. \n",
        "\n",
        "\tet_dim = d_embedding*(masked_transform_timesteps+1)\n",
        "\ttt_dim = d_embedding*(d_time_series_num+1)\n",
        "\n",
        "\t# Event transformer \n",
        "\n",
        "\tself.event_transformers = nn.ModuleList([x_transformers.Encoder(dim=et_dim, depth=1,\n",
        "\t\t\theads=n_transformer_head, pre_norm=norm_first, use_scalenorm=scalenorm,\n",
        "\t\t\tattn_dim_head=d_embedding//n_transformer_head, ff_glu=glu,\n",
        "\t\t\tff_mult=d_feedforward/et_dim, attn_dropout=transformer_dropout,\n",
        "\t\t\tff_dropout=transformer_dropout) for _ in range(n_duett_layers)])\n",
        "\n",
        "\t# Embedding layer for full events\n",
        "\n",
        "\tself.full_event_embedding = nn.Embedding(d_time_series_num + 1, et_dim)\n",
        "\n",
        "\t# Time transformer \n",
        "\n",
        "\tself.time_transformers = nn.ModuleList([x_transformers.Encoder(dim=tt_dim, depth=1,\n",
        "\t\t\theads=n_transformer_head, pre_norm=norm_first, use_scalenorm=scalenorm,\n",
        "\t\t\tattn_dim_head=d_embedding//n_transformer_head, ff_glu=glu,\n",
        "\t\t\tff_mult=d_feedforward/tt_dim, attn_dropout=transformer_dropout,\n",
        "\t\t\tff_dropout=transformer_dropout) for _ in range(n_duett_layers)])\n",
        "\n",
        "\t# Embedding layer for full time\n",
        "\n",
        "\tself.full_time_embedding =  self.cve(batch_norm=True, d_embedding=tt_dim)\n",
        "\tself.full_rep_embedding = nn.Embedding(tt_dim, 1)\n",
        "\n",
        "\t# time_series + static\n",
        "\n",
        "\td_representation = d_embedding * (d_time_series_num + 1) \n",
        "\tself.head = simple_mlp(d_representation, d_target, n_hidden_head, d_hidden_head,\n",
        "\t\t\thidden_batch_norm=True, final_activation=False, activation=nn.ReLU)\n",
        "\tself.pretrain_value_proj = simple_mlp(d_representation, d_time_series_num,\n",
        "\t\t\tpretrain_n_hidden, pretrain_d_hidden, hidden_batch_norm=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n",
        "\n",
        "The paper notes that the experiments are done on a single NVidia A6000 GPU. The most resource-intensive pre-training and fine-tuning procedure only uses 7GB of GPU memory and completes within two days.\n",
        "\n",
        "This notebook was ran with a GTX 1080 with 8GB of GPU Memory. Total training time ~6hrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretraining\n",
        "\n",
        "Uses masked event modeling to train the model to capture important priors. This masking scheme is done along both time and event dimensions and predicts both the presence and absence of an event. \n",
        "\n",
        "Max of 50 epochs while monitoring validation loss. Best model is saved as checkpoint.\n",
        "\n",
        "We use F.binary_cross_entropy_with_logits for loss and Adam for optimizer.\n",
        "\n",
        "Hyperparameters: lr=3.e-4, weight_decay=1.e-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(\"Current CUDA device: \", torch.cuda.current_device())\n",
        "print(\"Device name: \", torch.cuda.get_device_name(0))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpus = 1\n",
        "else:\n",
        "    gpus = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-training Code that monitors validation performance\n",
        "if training:\n",
        "\tpretrain_model = duett.pretrain_model(d_static_num=dm.d_static_num(),\n",
        "\t\t\td_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(),\n",
        "\t\t\tseed=seed)\n",
        "\tcheckpoint = pl.callbacks.ModelCheckpoint(save_last=True, monitor='val_loss', mode='min', save_top_k=1, dirpath='checkpoints')\n",
        "\twarmup = train.WarmUpCallback(steps=2000)\n",
        "\tlogger = CSVLogger(\"logs\", name=\"pre_train\")\n",
        "\ttrainer = pl.Trainer(gpus=gpus, logger=logger, num_sanity_val_steps=2, max_epochs=300,\n",
        "\t\t\tgradient_clip_val=1.0, callbacks=[warmup, checkpoint])\n",
        "\ttrainer.fit(pretrain_model, dm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if training:\n",
        "\tversions = [int(version.split(\"_\")[1]) for version in os.listdir(\"logs/pre_train\") if version.startswith(\"version_\")]\n",
        "\tversions.sort(reverse=True)\n",
        "\tfile_path = os.path.join(\"logs/pre_train\", f\"version_{versions[0]}\", \"metrics.csv\")\n",
        "else:\n",
        "\tfile_path = \"metrics/pre_train_metrics.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "val_loss = df['val_loss'].dropna().to_numpy()\n",
        "train_loss = df['train_loss'].dropna().to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize train/val loss metrics\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss, label='Train Loss', color='blue')\n",
        "plt.plot(val_loss, label='Validation Loss', color='orange')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if training:\n",
        "\tpretrained_path = checkpoint.best_model_path\n",
        "else:\n",
        "\tpretrained_path = \"checkpoints\\pretrained.ckpt\"\n",
        "\n",
        "print(\"Pre-trained Checkpoint Path: \", pretrained_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-Tuning\n",
        "\n",
        "Fine-tuning in a supervised manner after pretraining. We fine-tune on 3 seeds (2020, 2021, 2022), and take the average of the top 5 models from each to obtain the final model for that seed.\n",
        "\n",
        "Hyperparameters:\n",
        "epochs=50\n",
        "transformer_dropout=0.5\n",
        "lr=1.e-4\n",
        "weight_decay=1.e-5\n",
        "\n",
        "We measure the performence by AUROC and Average Precision on the validation set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tune and average model over 3 seeds (same as Paper)\n",
        "\n",
        "if training:\n",
        "\tfine_tune_losses = []\n",
        "\tfine_tune_auroc = []\n",
        "\tfine_tune_ap = []\n",
        "\n",
        "\tfine_tune_auroc1 = []\n",
        "\tfine_tune_ap1 = []\n",
        "\n",
        "\tfinal_models = []\n",
        "\n",
        "\tfor seed in range(2022, 2023):\n",
        "\t\tpl.seed_everything(seed)\n",
        "\t\tfine_tune_model = duett.fine_tune_model(pretrained_path, d_static_num=dm.d_static_num(),\n",
        "\t\t\t\td_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac(), seed=seed)\n",
        "\t\tfine_tune_model.train_loss = []\n",
        "\t\tfine_tune_model.val_loss = []\n",
        "\n",
        "\t\tpath = 'checkpoints/' + str(seed)\n",
        "\t\tos.makedirs(path, exist_ok=True)\n",
        "\n",
        "\t\tcheckpoint = pl.callbacks.ModelCheckpoint(save_top_k=5, save_last=False, mode='max', monitor='val_ap', dirpath=path)\n",
        "\t\twarmup = train.WarmUpCallback(steps=1000)\n",
        "\n",
        "\t\tlog_name = \"fine_tune_\" + str(seed)\n",
        "\n",
        "\t\tlogger = CSVLogger(\"logs\", name=log_name)\n",
        "\t\ttrainer = pl.Trainer(gpus=gpus, logger=logger, max_epochs=50, gradient_clip_val=1.0,\n",
        "\t\t\t\tcallbacks=[warmup, checkpoint])\n",
        "\t\ttrainer.fit(fine_tune_model, dm)\n",
        "\n",
        "\t\tfine_tune_losses.append(fine_tune_model.val_loss)\n",
        "\t\tfine_tune_auroc.append(fine_tune_model.epoch_val_auroc)\n",
        "\t\tfine_tune_ap.append(fine_tune_model.epoch_train_ap)\n",
        "\n",
        "\t\t# Get Final model from average weight of best models\n",
        "\t\tbest_models = checkpoint.best_k_models.keys() \n",
        "\n",
        "\t\tfinal_model = train.average_models([duett.fine_tune_model(path, d_static_num=dm.d_static_num(),\n",
        "\t\td_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac())\n",
        "\t\tfor path in best_models])\n",
        "\n",
        "\t\tfinal_models.append(final_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load fine-tune performance gain (AUROC, AP)\n",
        "val_auroc = []\n",
        "val_ap = []\n",
        "\n",
        "train_auroc = []\n",
        "train_ap = []\n",
        "\n",
        "for seed in range(2020, 2023):\n",
        "\tif training:\n",
        "\t\tlog_path = \"logs/fine_tune_\" + str(seed)\n",
        "\t\tversions = [int(version.split(\"_\")[1]) for version in os.listdir(log_path) if version.startswith(\"version_\")]\n",
        "\t\tversions.sort(reverse=True)\n",
        "\t\tfile_path = os.path.join(log_path, f\"version_{versions[0]}\", \"metrics.csv\")\n",
        "\telse:\n",
        "\t\tfile_path = \"metrics/fine_tune_\" + str(seed) + \"_metrics.csv\"\n",
        "\n",
        "\tdf = pd.read_csv(file_path)\n",
        "\n",
        "\tval_auroc.append(df['val_auroc'].dropna().to_numpy())\n",
        "\tval_ap.append(df['val_ap'].dropna().to_numpy())\n",
        "\n",
        "\ttrain_auroc.append(df['train_auroc'].dropna().to_numpy())\n",
        "\ttrain_ap.append(df['train_ap'].dropna().to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize AUROC & Avg Precision\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(3):\n",
        "\tplt.plot(val_auroc[i], label='Validation' if i == 0 else '', alpha=0.7, color='orange') \n",
        "\tplt.plot(train_auroc[i], label='Training' if i == 0 else '', alpha=0.7, color='blue') \n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('AUROC')\n",
        "plt.title('Fine-tuned Validation AUROC')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(3):\n",
        "\tplt.plot(val_ap[i], label='Validation' if i == 0 else '', alpha=0.7, color='orange') \n",
        "\tplt.plot(train_ap[i], label='Training' if i == 0 else '', alpha=0.7, color='blue') \n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Avg Precision')\n",
        "plt.title('Fine-tuned Validation Avg Precision')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Results\n",
        "\n",
        "Following Pre-training and Fine-Tuning, we run the 3 final models on the test set and measure the average/std of AUROC and Average Precision.\n",
        "\n",
        "We compare the results with XGBoost, LSTM, mTAND, Raindrop, STraTs on the PhysioNet-2012 mortality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get final model for each seed by averaging the weight of the best checkpoints\n",
        "if training:\n",
        "\tbest_models = final_models\n",
        "else:\n",
        "\tbest_models = []\n",
        "\n",
        "\tfor i in range(2020, 2023):\n",
        "\t\tif training:\n",
        "\t\t\tdir_path = 'checkpoints/' + str(i)\n",
        "\t\telse:\n",
        "\t\t\tdir_path = 'checkpoints/fine_tuned/' + str(i)\n",
        "\n",
        "\t\ttop_k = [os.path.join(dir_path, filename) for filename in os.listdir(dir_path)]\n",
        "\n",
        "\t\tprint(top_k)\n",
        "\n",
        "\t\tbest_models.append(train.average_models([duett.fine_tune_model(path, d_static_num=dm.d_static_num(),\n",
        "\t\t\td_time_series_num=dm.d_time_series_num(), d_target=dm.d_target(), pos_frac=dm.pos_frac())\n",
        "\t\t\tfor path in top_k]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run final model on test set\n",
        "test_auroc = []\n",
        "test_ap = []\n",
        "\n",
        "warmup = train.WarmUpCallback(steps=1000)\n",
        "trainer = pl.Trainer(gpus=gpus, logger=False,\n",
        "\t\tcallbacks=[warmup])\n",
        "\n",
        "for final_model in best_models:\n",
        "\tresult = trainer.test(final_model, dataloaders=dm)\n",
        "\n",
        "\ttest_auroc.append(result[0]['test_auroc'])\n",
        "\ttest_ap.append(result[0]['test_ap'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final results averaged over 3 seed (2020, 2021, 2022)\n",
        "\n",
        "print(\"Mean AUROC: \", f\"{np.mean(test_auroc):.3f} ± {np.std(test_auroc):.3f}\")\n",
        "print(\"Mean AP: \", f\"{np.mean(test_ap):.3f} ± {np.std(test_ap):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAWAy_LwHlV"
      },
      "source": [
        "## Model comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "source": [
        "PhysioNet-2012 Mortality Task Performance\n",
        "\n",
        "Below is our model's best performance compared with other methods. Other method's performance data is sourced from the original paper.\n",
        "All methods use seed 2020 with ours using seed 2020-2022.\n",
        "\n",
        "| Model           | ROC-AUC    | PR-AUC    |\n",
        "|-----------------|------------|-----------|\n",
        "| XGBoost         | 0.865 ± 0.001 | 0.531 ± 0.009 |\n",
        "| LSTM            | 0.848 ± 0.002 | 0.494 ± 0.002 |\n",
        "| mTAND           | 0.857 ± 0.001 | 0.515 ± 0.007 |\n",
        "| Raindrop         | 0.838 ± 0.009 | 0.479 ± 0.002 |\n",
        "| STraTS           | 0.852 ± 0.008 | 0.527 ± 0.006 |\n",
        "| DuETT (Ours)    | 0.872 ± 0.001** | 0.554 ± 0.003** |\n",
        "\n",
        "We see that our method achieves better results compared to all other methods on the AUROC and PR metric and matches the performance described in the paper.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This paper's results were reproducible due to the availability of the original code with all hyperparameter provided. We were able to achieve similar performance as the original paper and was able to achieve better performance on the Physio2012 Mortality task when compared with other methods.\n",
        "\n",
        "It was relatively simple to replicate the code and algorithm of the model. However, due to the lengthiness of the training process, our device would run out of memory and fail to complete the trainng. While we were able to use lighting module's checkpoint to recover the progress, some hiccups were introduced with metric tracking for visualization process. Some suggestion would also be to include more comments in the code for better readability as well as visualization of the data set and training process.\n",
        "\n",
        "In the next phase, we will conduct the following ablation studies, and report on the results.\n",
        "\n",
        "1.   Input representation ablations: \n",
        "      - Investigate the use of the last occurring value in the bin as the aggregation functions of bins by comparing the performance with other methods (mean, max). \n",
        "      - Investigate the choice of injecting event & time embedding at each layer which should by only injecting at the first layer.\n",
        "2.   Self-Supervised Learning Ablation: \n",
        "      - Investigate the impact of pre-training by skipping it entirely.\n",
        "3.   Dual event & time transformer Ablation: \n",
        "      - Investigate the impact of having both event and time transformers by only having either event or time transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1.   Labach, A., Pokhrel, A., Huang, X. S., Zuberi, S., Yi, S. E., Volkovs, M., Poutanen, T., & Krishnan, R. G. DuETT: Dual Event Time Transformer for Electronic Health Records. arXiv, 2023, arXiv:2304.13017, doi: https://doi.org/10.48550/arXiv.2304.13017\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
